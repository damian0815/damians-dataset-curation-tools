{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "#repo_id = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
    "#repo_id = \"laion/CLIP-ViT-g-14-laion2B-s12B-b42K\" # more modern CLIP model\n",
    "repo_id = \"openai/clip-vit-large-patch14-336\" # the CLIP model used for SD up to v1.5\n",
    "device = 'cuda'\n",
    "\n",
    "print(\"loading model...\")\n",
    "model = CLIPModel.from_pretrained(repo_id)\n",
    "print(\"loading preprocessor...\")\n",
    "processor = CLIPProcessor.from_pretrained(repo_id)\n",
    "\n",
    "print(f\"sending to {device}...\")\n",
    "model.half().to(device)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6971cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def resize_image(fullsize_image: PIL.Image, min_edge_length: int, max_edge_length: int=None) -> PIL.Image:\n",
    "    transform = transforms.Resize(size=min_edge_length, max_size=max_edge_length)\n",
    "    return transform(fullsize_image)\n",
    "\n",
    "\n",
    "\n",
    "def get_clip_image_features(image: PIL.Image) -> torch.Tensor:\n",
    "    preprocess_results = processor(text=None, \n",
    "                                   images=image, \n",
    "                                   return_tensors=\"pt\", \n",
    "                                   padding=True, \n",
    "                                   device=device\n",
    "                                  )\n",
    "    pixel_values = preprocess_results.pixel_values\n",
    "    #print(pixel_values.device)\n",
    "    image_features = model.get_image_features(pixel_values = pixel_values.half().to(model.device))\n",
    "    return image_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c840258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from async_video_processor import AsyncVideoProcessor\n",
    "\n",
    "\n",
    "accumulated_results = {}\n",
    "out_data = {}\n",
    "\n",
    "def process_func(frame_cv_bgr):\n",
    "    frame_cv_rgb = cv2.cvtColor(np.array(frame_cv_bgr), cv2.COLOR_BGR2RGB)    \n",
    "    pil_image = PIL.Image.fromarray(frame_cv_rgb)\n",
    "    features = get_clip_image_features(resize_image(pil_image, min_edge_length= 512))\n",
    "    \n",
    "    return features.detach().cpu()\n",
    "\n",
    "def results_func(frame_index, data):\n",
    "    accumulated_results[frame_index] = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418316bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def test_tqdm_manual():\n",
    "    pbar = tqdm(range(1000))\n",
    "    for i in range(1000):\n",
    "        pbar.update(1)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "test_tqdm_manual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "async def write_clip_features(root_path):\n",
    "    global accumulated_results\n",
    "    print(\"walking\", root_path)\n",
    "    for directory, _, filenames in os.walk(root_path):\n",
    "        video_extensions = [\".mp4\"]\n",
    "        print('directory:', directory)\n",
    "        video_filenames = [f for f in filenames if os.path.splitext(f)[1] in video_extensions]\n",
    "        if len(video_filenames)==0:\n",
    "            continue\n",
    "        for filename in tqdm(video_filenames, desc=directory):\n",
    "            video_path = os.path.join(directory, filename)\n",
    "            pickle_path = video_path + \".clip-features.pickle\"\n",
    "            if os.path.exists(pickle_path):\n",
    "                print(\"not overwriting existing\", pickle_path)\n",
    "                continue\n",
    "\n",
    "            accumulated_results = {}\n",
    "            process_fps = 0.5\n",
    "            first_frame_to_process = 0\n",
    "\n",
    "            def write_results_func(video, partial:bool):\n",
    "                if partial:\n",
    "                    return\n",
    "                outData = {\n",
    "                    'type': 'clip features ' + repo_id,\n",
    "                    'fps': video.get(cv2.CAP_PROP_FPS),\n",
    "                    'features': accumulated_results,\n",
    "                    'frameIncrement': frame_increment\n",
    "                }\n",
    "                \n",
    "                with open(pickle_path, 'wb') as handle:\n",
    "                    pickle.dump(outData, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"cumulative detection count:\",str(len(accumulated_results)))\n",
    "\n",
    "            async_video_processor = AsyncVideoProcessor(video_path, process_func, results_func, write_results_func, first_frame_to_process, process_fps)\n",
    "            frame_increment = async_video_processor.frameIncrement\n",
    "            await async_video_processor.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14a99b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "await write_clip_features(\"./videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ed838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
